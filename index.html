<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Practical Machine Learning Project by amak222</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Practical Machine Learning Project</h1>
        <h2>My machine learning (ML) class work</h2>
        <a href="https://github.com/amak222/Practical-ML-Class" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h3>
<a id="project-objective" class="anchor" href="#project-objective" aria-hidden="true"><span class="octicon octicon-link"></span></a>Project Objective</h3>

<p>The assignment requires to use the weight lifting exercise data set and create a classification algorithm. The algorithm 
is to classify the manner in which the subjects perform their exercise (correct and incorrect variations of the same 
exercise). The study subjects wore motion tracking devices in order to capture various data about their exercise. There 
are 5 class levels (variations of the same exercise) that are required for training the algorithm and using it to 
subsequently make predictions on 20 predetermined out-of-sample examples.</p>

<h3>
<a id="data" class="anchor" href="#data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data</h3>

<p>I downloaded the data sets "pml-training.csv" and "pml-testing.csv" directly to my hard-drive and then imported them into
my work directory in R.</p>

<p>Call the necessary libraries that will be used in the data exploration and algorithm training later.</p>

<pre><code>library(lattice)
library(ggplot2)
library(caret)
library(rpart)
library(rattle)
</code></pre>

<h3>
<a id="reading-the-files-into-the-work-directory" class="anchor" href="#reading-the-files-into-the-work-directory" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reading the Files Into the Work Directory</h3>

<p>Set Work Directory</p>

<pre><code>setwd("~/Career/Practical_Machine_Learning/Assignments")
</code></pre>

<p>Set the seed number if I would like to recreate the exact results later.</p>

<pre><code>set.seed(1357)
</code></pre>

<p>Read In The files</p>

<pre><code>d_trn &lt;- read.csv("pml-training.csv", header=TRUE,na.strings=c("NA","#DIV/0!",""))
d_tst &lt;- read.csv("pml-testing.csv", header=TRUE,na.strings=c("NA","#DIV/0!",""))
dim(d_trn); dim(d_tst)
</code></pre>

<p>Rows and columns</p>

<p>[1] 19622    160</p>

<p>[1]  20      160</p>

<p>160 features are present in the data. The data set with 20 observation will be used to perform the final prediction. 
The "d_trn" data will be be partitioned into training and testing 50/50. Conventionally, the split is typically 60/40,
but I decided to reduce the processing time (random forests take a long time) with the smaller training data set.
The partition is done on the classification target variable "classe."</p>

<h3>
<a id="data-partition" class="anchor" href="#data-partition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Partition</h3>

<pre><code>inTrain &lt;- createDataPartition(y=d_trn$classe, p=0.5, list=FALSE)
wkTraining &lt;- d_trn[inTrain, ]
wkTesting &lt;- d_trn[-inTrain, ]
dim(wkTraining); dim(wkTesting)
</code></pre>

<p>[1] 9812  160</p>

<p>[1] 9810  160</p>

<p>Upon preliminary data observation, I noticed quite a few field with statistical summaries like standard deviation
curtosis, etc that were derived from the primary exercise repetitions. Many of these fields contained "NA" values.
These fields are not very useful to make predictions unless the predictions are made on repetitive exercise and
not on a one-time observation similar to the ones in the 20 sample data. Features with NA of more than 50% of
observations as well as near zero variance field will be removed.</p>

<p>Among other irrelevant features were the features representing user names, date and time stamps and some indication what
observation window the measurements fell into. These predictors are highly correlated with the outcome variable because
that's how the experiment was designed and conducted. I will remove them accordingly.</p>

<h3>
<a id="near-zero-variance-predictors-nzv" class="anchor" href="#near-zero-variance-predictors-nzv" aria-hidden="true"><span class="octicon octicon-link"></span></a>Near Zero Variance Predictors (NZV)</h3>

<p>Let's determine what predictors have no or little variability in them</p>

<p>wkDataNZV &lt;- nearZeroVar(wkTraining, saveMetrics=TRUE)
   wkDataNZV</p>

<p>Remove the NZV and irrelevant predictors from the data</p>

<pre><code>wkNZVvars &lt;- names(wkTraining) %in%  c("new_window","num_window","kurtosis_yaw_belt","skewness_yaw_belt",
"amplitude_yaw_belt","avg_roll_arm","stddev_roll_arm","var_roll_arm","avg_pitch_arm","stddev_pitch_arm","var_pitch_arm",
"avg_yaw_arm","stddev_yaw_arm","var_yaw_arm","amplitude_roll_arm","kurtosis_yaw_dumbbell","skewness_yaw_dumbbel",
"amplitude_yaw_dumbbel","kurtosis_yaw_forearm","skewness_yaw_forearm","amplitude_roll_forearm","amplitude_yaw_forearm",
"avg_roll_forearm","stddev_roll_forearm","var_roll_forearm","avg_pitch_forearm","stddev_pitch_forearm",
"var_pitch_forearm","avg_yaw_forearm","stddev_yaw_forearm","var_yaw_forearm","min_pitch_arm","skewness_yaw_dumbbell",
"amplitude_yaw_dumbbell",
#irrelevant features
"X","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","user_name")
</code></pre>

<p>wkTraining &lt;- wkTraining[!wkNZVvars]</p>

<p>I will also eliminate predictors where NA &gt;= 51%</p>

<pre><code>hldTraining &lt;- wkTraining
for(i in 1:length(wkTraining)) 
{ if(sum( is.na(wkTraining[, i] ) ) /nrow(wkTraining) &gt;= .51 ) #NAs &gt; 51% of total Ns
{for(j in 1:length(hldTraining))
{if(length( grep(names(wkTraining[i]), names(hldTraining)[j]) ) ==1)  #if same name
{hldTraining &lt;- hldTraining[ , -j] #Remove that variable}   
 }      }}

dim(hldTraining)
</code></pre>

<p>[1] 9812   53</p>

<pre><code>rm(wkTraining)
wkTraining &lt;- hldTraining
rm(hldTraining)
</code></pre>

<p>Only 53 features remain in the data after irrelevant predictors have been removed.</p>

<h3>
<a id="bootstrapping-of-the-training-data" class="anchor" href="#bootstrapping-of-the-training-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bootstrapping of the Training Data</h3>

<p>As an experiment, I decided to bootstrap my training data in an effort to cross validate the quality of some algorithms
I will be building. This is a good check for how the error will behave under an out-of-sample scenario. </p>

<pre><code>fitControl &lt;- trainControl(
                       method = "repeatedcv",
                       number = 4,
                       repeats = 4)
</code></pre>

<p>The fitControl object will be later applied to a boosting algorithm.</p>

<h2>
<a id="machine-learning-algorithms" class="anchor" href="#machine-learning-algorithms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning Algorithms</h2>

<p>I will train three algorithms - </p>

<ol>
<li><p>Decision Tree</p></li>
<li><p>Random Forests</p></li>
<li><p>Boosting</p></li>
</ol>

<p>Before I proceeded, I ran a descriptive statistics analysis. The analysis revealed that 4 predictors were highly correlated (&gt;.9) with some of the other predictors. I will eliminate those because they do not carry any additional information signal.</p>

<p>Removing highly correlated features</p>

<pre><code>wkTraining &lt;- subset(wkTraining,select=-c(gyros_belt_x,gyros_belt_y,magnet_dumbbell_x,magnet_dumbbell_y))
</code></pre>

<h3>
<a id="1-decision-tree-dt" class="anchor" href="#1-decision-tree-dt" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. DECISION TREE (DT)</h3>

<pre><code>mod_DT &lt;- train(wkTraining$classe ~ ., method="rpart",data=wkTraining)
print(mod_DT)

CART 
9812 samples
48 predictor
5 classes: 'A', 'B', 'C', 'D', 'E' 

No pre-processing
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 9812, 9812, 9812, 9812, 9812, 9812, ... 

Resampling results across tuning parameters:
 cp          Accuracy   Kappa       Accuracy SD  Kappa SD  
0.02242951  0.6067790  0.49993101  0.04281592   0.06093116
0.02734264  0.5613997  0.43881968  0.06190937   0.09270286
0.11777271  0.3343041  0.07564283  0.03972848   0.06310175

Accuracy was used to select the optimal model using  the largest value. The final value used for the model was cp =0.02242951. 

n= 9812
</code></pre>

<p>Visualize the trained decision tree</p>

<pre><code>fancyRpartPlot(mod_DT$finalModel)
</code></pre>

<p><img src="https://cloud.githubusercontent.com/assets/13913064/9426027/081eb286-48ee-11e5-8931-294bf5acd5ca.jpeg" alt=""></p>

<p>Assess the performance on the testing data</p>

<pre><code>prd_DT &lt;- predict(mod_DT, newdata=wkTesting)
DT_CMX &lt;- confusionMatrix(prd_DT, wkTesting$classe)
DT_CMX
</code></pre>

<p>Confusion Matrix and Statistics</p>

<pre><code>Reference
Prediction    A    B    C    D    E
     A 2248  635   83  211   92
     B   25  808   42  150  455
     C  467  409 1385  504  365
     D   42   46  201  743   93
     E    8    0    0    0  798
</code></pre>

<p>Overall Statistics</p>

<pre><code> Accuracy : 0.6098          
 95% CI : (0.6001, 0.6195)
No Information Rate : 0.2844          
P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
              Kappa : 0.5039          
 Mcnemar's Test P-Value : &lt; 2.2e-16       
</code></pre>

<p>Statistics by Class:</p>

<pre><code>                 Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.8057  0.42571   0.8095  0.46206  0.44260
Specificity            0.8546  0.91507   0.7845  0.95343  0.99900
Pos Pred Value         0.6877  0.54595   0.4425  0.66044  0.99007
Neg Pred Value         0.9171  0.86915   0.9512  0.90040  0.88838
Prevalence             0.2844  0.19348   0.1744  0.16391  0.18379
Detection Rate         0.2292  0.08236   0.1412  0.07574  0.08135
Detection Prevalence   0.3332  0.15087   0.3191  0.11468  0.08216
Balanced Accuracy      0.8301  0.67039   0.7970  0.70775  0.72080
</code></pre>

<p>Achieved accuracy is .61 in testing and the confusion matrix shows that many cases are misclassified. Possibly a different approach is necessary.</p>

<h3>
<a id="2-random-forests-rf" class="anchor" href="#2-random-forests-rf" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. RANDOM FORESTS (RF)</h3>

<pre><code>mod_RF &lt;- train(classe ~. , method="rf", data=wkTraining, prox=TRUE)
prd_RF &lt;- predict(mod_RF, wkTesting)
RF_CMX &lt;- confusionMatrix(prd_RF, wkTesting$classe)
RF_CMX
</code></pre>

<p>Confusion Matrix and Statistics</p>

<pre><code>      Reference
Prediction    A    B    C    D    E
        A 2778   28    0    0    0
        B   11 1854   16    3    5
        C    1   13 1688   14    7
        D    0    2    7 1585    5
        E    0    1    0    6 1786
</code></pre>

<p>Overall Statistics</p>

<pre><code>     Accuracy : 0.9879          
     95% CI : (0.9855, 0.9899)
No Information Rate : 0.2844          
P-Value [Acc &gt; NIR] : &lt; 2.2e-16       

              Kappa : 0.9847          
 Mcnemar's Test P-Value : NA              
</code></pre>

<p>Statistics by Class:</p>

<pre><code>                 Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9957   0.9768   0.9866   0.9857   0.9906
Specificity            0.9960   0.9956   0.9957   0.9983   0.9991
Pos Pred Value         0.9900   0.9815   0.9797   0.9912   0.9961
Neg Pred Value         0.9983   0.9944   0.9972   0.9972   0.9979
Prevalence             0.2844   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2832   0.1890   0.1721   0.1616   0.1821
Detection Prevalence   0.2860   0.1926   0.1756   0.1630   0.1828
</code></pre>

<p>Balanced Accuracy      0.9959   0.9862   0.9911   0.9920   0.9948</p>

<p>The RF algorithm took a while to run, but the results look promising on the testing data. Achieved accuracy = .988 and somewhat a small number of cases were misclasified as shown by the confusion matrix</p>

<h3>
<a id="3-gradient-boosting-model-with-boot-strapping" class="anchor" href="#3-gradient-boosting-model-with-boot-strapping" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. GRADIENT BOOSTING MODEL WITH BOOT-STRAPPING</h3>

<pre><code>mod_B_cv &lt;- train(wkTraining$classe ~ ., data=wkTraining, method="gbm", trControl = fitControl, verbose=FALSE)

prd_B_cv &lt;- predict(mod_B_cv, wkTesting)
B_CMX_cv &lt;- confusionMatrix(prd_B_cv, wkTesting$classe)
B_CMX_cv
</code></pre>

<p>Confusion Matrix and Statistics</p>

<pre><code>      Reference
Prediction    A    B    C    D    E
         A 2719   85    4    2   10
         B   49 1750   52    6   28
         C   16   57 1636   38   17
         D    3    3   14 1554   30
         E    3    3    5    8 1718
</code></pre>

<p>Overall Statistics</p>

<pre><code>           Accuracy : 0.9559          
             95% CI : (0.9516, 0.9598)
  No Information Rate : 0.2844          
  P-Value [Acc &gt; NIR] : &lt; 2.2e-16       

              Kappa : 0.9442          
 Mcnemar's Test P-Value : 1.398e-11       
</code></pre>

<p>Statistics by Class:</p>

<pre><code>                 Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9746   0.9220   0.9562   0.9664   0.9529
Specificity            0.9856   0.9829   0.9842   0.9939   0.9976
Pos Pred Value         0.9642   0.9284   0.9274   0.9688   0.9891
Neg Pred Value         0.9898   0.9813   0.9907   0.9934   0.9895
Prevalence             0.2844   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2772   0.1784   0.1668   0.1584   0.1751
Detection Prevalence   0.2875   0.1922   0.1798   0.1635   0.1771
Balanced Accuracy      0.9801   0.9525   0.9702   0.9802   0.9752
</code></pre>

<p>The boosting algorithm performed well, but it was not as accurate as the random forests. The acheived accuracy was 0.96. I also ran a boosting algorithm, but without the boot strapping component and the accuracy went down to 0.95. The boot strapping impact was rather small.</p>

<p>After comparing the predictive accuracy for each 4 algorithms I ran, I selected the highest accuracy with the RF algorithm. I feel comfortable using accuracy in this case because our outcome classes were not rare events.</p>

<p>Finally, I used the RF and Boosting algorithms to produce prediction on the 20 held out examples. They both produced identical predictions below.</p>

<pre><code>prd_1 &lt;- predict(mod_RF, newdata = d_tst)
prd_2 &lt;- predict(mod_B_cv, newdata = d_tst)
prd_1; prd_2
[1] B A B A A E D B A A B C B A E E A B B B

[1] B A B A A E D B A A B C B A E E A B B B

Levels: A B C D E
</code></pre>

<p>Jeff Leek provides a sample code that creates text files with predictions. The individual text files are uploaded to the Coursera class web site.</p>

<h3>
<a id="writing-the-answers-into-a-text-file" class="anchor" href="#writing-the-answers-into-a-text-file" aria-hidden="true"><span class="octicon octicon-link"></span></a>Writing the answers into a text file</h3>

<pre><code>pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
 filename = paste0("problem_id_",i,".txt")
  write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
    }
 }

pml_write_files(prd_1) #predictions from the random forest algorithm
</code></pre>

<h2>
<a id="end" class="anchor" href="#end" aria-hidden="true"><span class="octicon octicon-link"></span></a>END</h2>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/amak222/Practical-ML-Class/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/amak222/Practical-ML-Class/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/amak222/Practical-ML-Class"></a> is maintained by <a href="https://github.com/amak222">amak222</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
